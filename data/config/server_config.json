{
  "host": "0.0.0.0",
  "port": 9006,
  "models": [
    {
      "model": "/data/CSY/autodefense/AutoDefense/llama_models/llama-pro-8b-instruct.Q8_0.gguf",
      "model_alias": "llama-pro-8b",
      "chat_format": "zephyr",
      "n_gpu_layers": -1,
      "offload_kqv": true,
      "n_threads": 32,
      "n_batch": 512,
      "n_ctx": 4096
    }
    
  ]
}